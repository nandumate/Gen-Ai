# 🧠✨ Generative AI Assignments

This repository contains a curated set of Generative AI assignments demonstrating hands-on implementation of cutting-edge techniques in prompt engineering, generative modeling, diffusion-based image synthesis, text-to-speech, and multimodal learning.

---

## 📚 Assignment Overview

### ✅ Assignment 1: Probabilistic Generative Model OR Markov Chain Text Generator
- Implemented a **Text Generator using Markov Chains**.
- Trained on a custom corpus to generate new sentences based on probabilistic state transitions.

---

### ✅ Assignment 2: Prompt Engineering Techniques
- Implemented and analyzed the following prompt engineering strategies:
  - **Interview Approach**
  - **Chain-of-Thought (CoT)**
  - **Tree-of-Thought (ToT)**
- Also demonstrated:
  - **Zero-Shot Prompting**
  - **Few-Shot Prompting**
- Compared performance across multiple NLP tasks such as arithmetic, commonsense reasoning, and story continuation.

---

### ✅ Assignment 3: Fine-tuning GPT/GPT-2 for Story Generation
- Used Hugging Face’s `transformers` library to fine-tune **GPT-2** on a creative story dataset.
- Customized training for style and tone.
- Generated new stories with creative plot lines.

---

### ✅ Assignment 4: QA Chatbot using Pre-trained LLM
- Built a **question-answering chatbot** using models like **BERT** or **T5**.
- Included context-aware response generation.
- Leveraged Hugging Face’s pipelines and Flask (optional) for deployment.

---

### ✅ Assignment 5: Creative Artwork with Diffusion Models
- Implemented creative image generation using **Stable Diffusion**.
- Modified the pre-trained model for custom styles and image control.

---

### ✅ Assignment 6: Text-to-Image Generation using DALL·E
- Built a pipeline using **OpenAI’s DALL·E** or **Mini DALL·E (DALLE-pytorch)**.
- Converted creative text prompts into unique images.


---

### ✅ Assignment 7: Multimodal Image Captioning using CLIP
- Implemented a **basic image captioning system** using **CLIP** embeddings and a language model (e.g., GPT-2).
- Combined vision-language reasoning for caption generation.


---

### ✅ Assignment 8: Text-to-Speech with Tacotron/WaveNet
- Developed a **text-to-speech pipeline** using **Tacotron 2** and/or **WaveNet**.
- Converted arbitrary text into realistic audio.
- Used pre-trained checkpoints for quick synthesis.


---

### ✅ Assignment 9: Video Animation using AI Tools
- Used an **AI animation tool** (e.g., **Runway ML**, **AnimAI**, or **Pika Labs**) to generate **video animations** from text/image prompts.
- Explored the creative use of AI in multimedia storytelling.

---

### ✅ Assignment 10: Multimodal Exploration via Transformer-based Text-to-Image
- Created images from text using transformer-based models.
- Investigated the **cross-modal capabilities** of vision-language transformers like **DALL·E**, **Imagen**, or **Stable Diffusion**.
- Demonstrated how transformers handle vision+language fusion.


---

## 🛠️ Requirements

Install dependencies using:
```bash
pip install -r requirements.txt
